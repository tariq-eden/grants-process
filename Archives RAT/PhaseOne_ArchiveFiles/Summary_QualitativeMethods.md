# repliCATS Phase One Qualitative Reserach Methods Summary

## Context for qualitative research decisions in the repliCATS project
To complement the quantitative research questions within the repliCATS project, a qualitative approach was incorporated to investigate the reasoning contributing to predictions about the replicability of research claims.  

In this context, the primary data amenable to qualitative analysis was the textual data collected through the free-text responses that participants provided, along with numerical estimates, about the likely replicability of specific research claims (on the repliCATS platform variation on the IDEA protocol). This large data set was supplemented by interviewes with a sub-set of the participants in repliCATS workshops. More detail on the data-collection process has been documented under ‘Elicitation’. The following details are provided as an overview of how this textual data was analysed.  

While distinguishing between qualitative and quantifiable approaches can become ambiguous in practice, it is an influential way of differentiating between research involving non-numerical data, such as text and images and those that focus on data that can be handled numerically (Schwandt 2001; Vogt and Johnson 2016). As such, textual analysis is often considered qualitative simply due to involving non-numerical data, yet there is a wide range of approaches to analysing textual data within the qualitative methods literature. For example, within the social sciences it is common to focus on the frequency of various analytic categories (including term use or instances of types-of-responses). Meanwhile, within the humanities, qualitative approaches tend to examine the contextualised content of textual data (including adapting hermeneutic approaches to interpreting texts or following phenomenological traditions that emphasise descriptive accounts of subjective experiences). [1]   

Drawing on this literature, our approach incorporated contextualised content-analysis techniques for systematically interpreting textual data by developing rules for multiple analysts to consistently index (‘code’) content within passages of textual data in ways that supports convergent analyses of those texts. This approach identifies the appearance of content-types within text using a set of analytic categories (‘codes’), yet that goes beyond calculating the frequency of the application of such codes to interpret the underlying content of that text within the relevant context (Hsieh and Shannon 2005). In interpreting the implicit meaning of texts, we followed existing guidelines by combining provisional coding for predefined grammatical and elemental codes with an exploratory stage of indexing additional content of relevance to the research questions (Saldaña 2016). This process went beyond providing instructions for identifying the appearance of terms (e.g., plausible) in the text, to specify synonymous terms and guide interpretation of implicit references to the category of analysis (e.g., content relevant to the category of plausibility might include texts such as ‘reason to believe’, ‘seemed reasonable’, and so on). This type of structured approach aligns with a process for qualitative content-analysis that has been described as “a research technique for making replicable and valid inferences from [a set of] text to their content” (Popping 2000, 7). 

This system of analysis was formalised by developing a codebook specifying the inclusion and exclusion criteria for those codes most relevant to our research questions. To ensure the stability of these codes for reliably reflecting the content of the textual data collected, at an appropriate level of complexity, this codebook emerged through an iterative process where several different analysts independently analysed subsections of the data and then compared which codes each applied to the same sections of text. In addition, each of these codes was assessed for inter-coder-reliability (ICR) at various points in this process. For example, when multiple analysts used a key version of the codebook to index the same subset of the texts, the ICR of each code was calculated. The ICR results contributed to reviewing the convergence of textual interpretation between analysts. In addition, when this process included analysts naive to the codebook development, ICR calculations provided an indication of which analytic categories required further calibration and which could function as a reliable tool interpreting the text in relation to our research questions for multiple analysts.

The value of transparent process and the potential of re-analysing textual data is well-recognised within qualitative research practices even though it is not relevant for all studies (Wästerfors, Åkerström, and Jacobsson 2014; Dag Stenvoll and Peter Svensson 2011). Therefore, in addition to calibrating our codebook to support multiple analysts converging upon consistent interpretations of the text, we also documented the decisions made during the codebook development and further analysis. This includes the current documentation on how the textual data was indexed, as well as the archived versions of our codebooks, to support re-analysis by those interested in our research questions. However, given the amount and richness of the textual data collected, there would also be value in re-indexing the data with the goal of examining different research questions entirely. Either way, by documenting the indexing process, we hope that any additional analyses of this textual data will have the benefit of potential cross-references with the analysis already conducted. 

## Data Collection Process 

## Data Processing Pipeline
### Integration of qualitative analysis data into repliCATS aggregation methods 
To do: copy figure from Aggregation Documentation  

### Data-processing using Computer-Aided Qualitative Data Analysis Software (CAQDAS): 
To do: 
- create pipeline visualisation 
- summarise data-input types

## Qualitative Analysis Process 
### Developing key analytic categories 
We developed a codebook that specifes the analytic categories used to interpret the textual data collected during the repliCATS project. The development of this codebook, and use of relevant analytic categories, can be summarised in terms of the qualitative analytic task types by Woolf and Silver (2017). 

### Interpretative categorisation of textual-platform-data by human-analysts (using Codebook V10) 
### Automated categorisation of textual-platform-data using 'reasonWAgg categories' based on human-analysed textual platform data. 

### Computer-aided Qualitative Analysis Software (CAQAS) troubleshooting 

## Bibliography
 Dag Stenvoll, and Peter Svensson. 2011. ‘Contestable Contexts: The Transparent Anchoring of Contextualization in Text-as-Data’. Qualitative Research 11 (5): 570–86. https://doi.org/10.1177/1468794111413242.
 
Forrester, Michael A., ed. 2010. Doing Qualitative Research in Psychology: A Practical Guide. Los Angeles; London: SAGE.

Hsieh, Hsiu-Fang, and Sarah E. Shannon. 2005. ‘Three Approaches to Qualitative Content Analysis’. Qualitative Health Research 15 (9): 1277–88. https://doi.org/10.1177/1049732305276687.

Popping, Roel. 2000. Computer-Assisted Text Analysis. SAGE.

Saldaña, Johnny. 2016. The Coding Manual for Qualitative Researchers. 3E [Third edition]. Los Angeles ; London: SAGE.

Schwandt, Thomas A. 2001. Dictionary of Qualitative Inquiry. 2nd ed. Thousand Oaks, Calif: Sage Publications.
Vogt, W. Paul, and R. Burke Johnson. 2016. The Sage Dictionary of Statistics & Methodology: A Nontechnical Guide for the Social Sciences. Fifth Edition. Thousand Oaks, California: SAGE Publications, Inc.

Wästerfors, David, Marlin Åkerström, and Katarina Jacobsson. 2014. ‘Reanalysis of Qualitative Data’. In The SAGE Handbook of Qualitative Data Analysis, edited by Uwe Flick, Katie Metzler, and Wendy Scott, 467–80. London, [England]: SAGE.

Woolf, Nicholas H., and Christina Silver. 2017. Qualitative Analysis Using NVivo: The Five-Level QDA Method. Developing Qualitative Inquiry. New York: Routledge.


[1] Given these traditions, qualitative studies are often considered to rely upon a relativistic epistemology. However, qualitative methods can be, and are, used within a range of theoretical frameworks: from strong social construction to positivist style realism, as well as – more recently – various approaches that seek to side-step this dichotomy (Forrester 2010, 18–32).
